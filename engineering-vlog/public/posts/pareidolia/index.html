<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><title>
         How LLMs See Illusory Faces
        
    </title><meta content="How LLMs See Illusory Faces" property=og:title><meta content="Videocall Engineering" property=og:description><meta content="Videocall Engineering" name=description><link href=/icon/favicon.png rel=icon type=image/png><link href=https://engineering.videocall.rs/fonts.css rel=stylesheet><link title="Videocall Engineering" href=https://engineering.videocall.rs/atom.xml rel=alternate type=application/atom+xml><link href=https://engineering.videocall.rs/theme/light.css rel=stylesheet><link href=https://engineering.videocall.rs/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://engineering.videocall.rs/js/themetoggle.js></script><script>setTheme(getSavedTheme());</script><link href=https://engineering.videocall.rs/main.css media=screen rel=stylesheet><script data-cf-beacon='{"token": "37a0f981a37240aea00b781e300bc6c0"}' defer src=https://static.cloudflareinsights.com/beacon.min.js></script></head><script>// Function to set the theme
        function setTheme(theme) {
            document.documentElement.className = theme;
            localStorage.setItem('theme', theme);
        }

        // Function to get the saved theme
        function getSavedTheme() {
            return localStorage.getItem('theme') || 'light';
        }

        // Set the theme on page load
        document.addEventListener('DOMContentLoaded', (event) => {
            setTheme(getSavedTheme());
        });</script><body><div class=content><header><div class=main><a href=https://engineering.videocall.rs>Videocall Engineering</a><div class=socials><a class=social href=https://twitter.com/emportent rel=me> <img alt=x src=https://engineering.videocall.rs/social_icons/x.svg> </a><a class=social href=https://github.com/altunenes rel=me> <img alt=github src=https://engineering.videocall.rs/social_icons/github.svg> </a><a href="https://scholar.google.com/citations?user=_OtEw5oAAAAJ&hl" class=social rel=me> <img alt=scholar src=https://engineering.videocall.rs/social_icons/googlescholar.svg> </a><a class=social href=https://www.linkedin.com/in/enes-altun-0a3076167 rel=me> <img alt=linkedin src=https://engineering.videocall.rs/social_icons/linkedin.svg> </a><a class=social href=https://www.instagram.com/altunanes/ rel=me> <img alt=instagram src=https://engineering.videocall.rs/social_icons/instagram.svg> </a><a class=social href=https://orcid.org/0000-0002-6478-6909 rel=me> <img alt=orcid src=https://engineering.videocall.rs/social_icons/orcid.svg> </a><a class=social href=https://www.shadertoy.com/user/altunenes rel=me> <img alt=shadertoy src=https://engineering.videocall.rs/social_icons/shadertoy.svg> </a><a class=social href=https://bsky.app/profile/altunenes.bsky.social rel=me> <img alt=bluesky src=https://engineering.videocall.rs/social_icons/bluesky.svg> </a></div></div><nav><a href=https://engineering.videocall.rs/posts style=margin-left:.7em>/posts</a><a href=https://engineering.videocall.rs/projects style=margin-left:.7em>/projects</a><a href=https://engineering.videocall.rs/about style=margin-left:.7em>/about</a><a href=https://engineering.videocall.rs/tags style=margin-left:.7em>/tags</a><a href=https://engineering.videocall.rs/CV style=margin-left:.7em>/CV</a><button aria-label="Toggle dark mode" id=dark-mode-toggle onclick=toggleTheme();><img alt="Light mode" id=sun-icon src=https://engineering.videocall.rs/feather/sun.svg> <img alt="Dark mode" id=moon-icon src=https://engineering.videocall.rs/feather/moon.svg></button></nav></header><script>function toggleTheme() {
    const html = document.documentElement;
    const currentTheme = html.classList.contains('dark') ? 'dark' : 'light';
    const newTheme = currentTheme === 'light' ? 'dark' : 'light';
    
    html.classList.remove(currentTheme);
    html.classList.add(newTheme);
    
    localStorage.setItem('theme', newTheme);
    updateThemeToggleIcons();
}

function updateThemeToggleIcons() {
    const sunIcon = document.getElementById('sun-icon');
    const moonIcon = document.getElementById('moon-icon');
    const isDarkMode = document.documentElement.classList.contains('dark');
    
    sunIcon.style.display = isDarkMode ? 'none' : 'inline';
    moonIcon.style.display = isDarkMode ? 'inline' : 'none';
}

// Set initial theme
const savedTheme = localStorage.getItem('theme') || 'light';
document.documentElement.classList.add(savedTheme);
updateThemeToggleIcons();</script><main><article><div class=title><div class=page-header>How LLMs See Illusory Faces<span class=primary-color style=font-size:1.6em>.</span></div><div class=meta>Posted on <time>2025-06-22</time></div></div><h1>Table of Contents</h1><ul><li><a href=https://engineering.videocall.rs/posts/pareidolia/#background> Background </a><li><a href=https://engineering.videocall.rs/posts/pareidolia/#what-is-spatial-frequency-and-coarse-to-fine-theory> What is Spatial Frequency and Coarse-to-Fine Theory? </a><li><a href=https://engineering.videocall.rs/posts/pareidolia/#how-llms-see-illusions> How LLMs see illusions </a><li><a href=https://engineering.videocall.rs/posts/pareidolia/#the-experiment> The Experiment </a> <ul><li><a href=https://engineering.videocall.rs/posts/pareidolia/#test-1-the-wire-face> Test 1: The Wire Face </a><li><a href=https://engineering.videocall.rs/posts/pareidolia/#test-2-the-church-face> Test 2: The Church Face </a><li><a href=https://engineering.videocall.rs/posts/pareidolia/#test-3-the-oval-hypothesis> Test 3: The Oval Hypothesis </a><li><a href=https://engineering.videocall.rs/posts/pareidolia/#test-4-the-illusory-robot> Test 4: The Illusory Robot </a><li><a href=https://engineering.videocall.rs/posts/pareidolia/#test-5-the-holistic-face-paintings> Test 5: The Holistic Face Paintings </a></ul><li><a href=https://engineering.videocall.rs/posts/pareidolia/#conclusion-and-final-thoughts> Conclusion and Final Thoughts </a></ul><section class=body><h4 id=background><span style=color:orange> Background </span></h4><p>Seeing faces in inanimate objects —a phenomenon called pareidolia— is a common human experience. With today's powerful Vision-Language Models (VLMs), a simple question arises: do they see these illusory faces too? Probing their "vision" this way isn't just a fun experiment. It's a practical way to understand their inner workings, challenge our assumptions when building with them, and explore the gap between artificial and biological sight.<p>This question grew out of my master's research, where I used EEG to study how the human brain processes these very illusions, which led to an <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4341900">ERP paper</a> on the topic.<h4 id=what-is-spatial-frequency-and-coarse-to-fine-theory><span style=color:orange> What is Spatial Frequency and Coarse-to-Fine Theory? </span></h4><p>So, how do you fairly test an AI's perception? My plan was to see if it falls for the same visual shortcuts our brains do.<p>This is based on a key idea in human vision called the <strong>Coarse-to-Fine</strong> theory. In short, human brain processes the blurry, general, coarse, "gist" of something first, and then uses that initial guess to figure out the finer details more quickly. The technical way to separate the "gist" from the "details" is with <strong>spatial frequencies</strong>, which can be isolated using techniques like 2D Fourier filtering.<ul><li><strong>Low Spatial Frequencies (LSF)</strong> are the blurry, large-scale shapes.<li><strong>High Spatial Frequencies (HSF)</strong> are the sharp edges and fine textures.</ul><p>You experience this all the time. Think about recognizing someone from across the street—you see their overall shape long before you see their eyes. While not about spatial frequency directly, a study on hierarchical processing shows a similar "general first" principle: people can spot an <em>animal</em> in an image in just 120ms, but need longer to identify it as a <em>dog</em> (<a href=https://pubmed.ncbi.nlm.nih.gov/25208739/>Wu et al., 2014</a>).<p>My whole experiment was designed around this: would the AI also see a face in the blur, but get confused by the sharp details? To test this, I needed to isolate these frequencies.<table><thead><tr><th style=text-align:center><img alt=SF src=/images/sf.png><tbody><tr><td style=text-align:center><em>Visualizing the Coarse-to-Fine theory. The left shows an image broken into coarse (Low Frequency) and fine (High Frequency) information. The right shows how the brain processes the coarse 'gist' first to guide perception.</em></table><p>To do this, I used a Butterworth filter from my own Rust tool, which you can try out here: <a href=https://altunenes.github.io/butter2d/>butter2d</a>.<h4 id=how-llms-see-illusions><span style=color:orange> How LLMs see illusions </span></h4><p>Research shows that modern VLMs are not objective, infallible observers; they can be "fooled" by classic visual illusions, and their susceptibility often increases with model scale <a href=https://arxiv.org/abs/2311.00047>Shen et al., 2023</a> . This suggests they are learning statistical heuristics from their training data that mimic human perception, rather than developing a deep, structural understanding of the world.<p>This makes pareidolia a particularly interesting test. It's not a geometric trick, but an illusion driven by a powerful, top-down, and likely evolutionary bias to find faces in our environment.<h3 id=the-experiment><span style=color:orange> The Experiment </span></h3><p>To test how Gemini handles pareidolia, I took several images and created three versions of each (using butterworth filter): the original <strong>Broadband (BB)</strong>, a blurry <strong>Low Spatial Frequency (LSF)</strong> version, and a sharp-edged <strong>High Spatial Frequency (HSF)</strong> version. I then fed them to the model with a simple prompt. To avoid any "memory" or context-priming effects, each images was processed in a completely separate session.<p>Here was the prompt:<blockquote><p>"What are the three most prominent objects you see in this image? Respond in a JSON format where each object has a 'name' and a 'confidence_score'."</blockquote><p>Here are the results.<h4 id=test-1-the-wire-face><span style=color:orange> Test 1: The Wire Face </span></h4><p>This image of server cables, which I found on X (formerly Twitter), has an uncanny facial structure. As hypothesized, the LLM completely missed the face in the broadband and HSF versions, describing only the literal content. However, when presented with the LSF version, where only the coarse, global shape remains, it immediately and confidently identified a <strong>"Face"</strong>. So the fine HSF details of the wires and components seem to break the illusion for the model, while the blurry LSF version provides the ideal template for a face.<table><thead><tr><th style=text-align:center><img alt=W src=/images/W.png><tbody><tr><td style=text-align:center><em>LSF (left), Broadband (middle), HSF (right) versions of the 'Wire Face'.</em></table><h4 id=test-2-the-church-face><span style=color:orange> Test 2: The Church Face </span></h4><p>Next, I used one of the most famous pareidolia images on the internet. My rationale was that if the model's perception is purely a function of its training data, it would have surely seen this image and would recognize the face (or illusory face). Once again, it failed to see the face in the BB and HSF versions, focusing only on the architecture. But in the LSF version, it correctly identified a <strong>"Face (Pareidolia)"</strong>. This suggests the model's failure isn't just about a lack of training data. The high-frequency details of the building's facade actively mask the illusion for the AI, even for a classic example.<table><thead><tr><th style=text-align:center><img alt=C src=/images/C.png><tbody><tr><td style=text-align:center><em>The famous 'Church Face' pareidolia.</em><br><em>Note that the model only sees a "Face (Pareidolia)" in the LSF version, describing only architectural elements in the others.</em></table><h4 id=test-3-the-oval-hypothesis><span style=color:orange> Test 3: The Oval Hypothesis </span></h4><p>The previous results sparked a new idea: perhaps the LLM's internal "face template" is strongly biased towards the oval, rounded shapes of human faces? The "Wire Face" is very angular. To test this, I selected two images with a more circular structure.<p>The first, an electrical component, followed the now-established pattern. A <strong>"Illusory Face"</strong> was detected in the LSF version, but the BB and HSF versions were seen only as literal machine parts.<table><thead><tr><th style=text-align:center><img alt=E src=/images/E.png><tbody><tr><td style=text-align:center><em>An illusory face in an electrical component.</em><br><em>The LSF version triggered a "Pareidolia Face" detection, while the detailed versions only yielded descriptions of machine parts.</em></table><p>The second image, however, gave a breakthrough result. This time, the LLM saw a face in <strong>all three versions!</strong> It identified a "Face" in both LSF and BB, and even a <strong>"Illusory Face"</strong> in the sharp HSF image. This is a brilliant finding. It suggests that when an object's structure is a strong enough match for the AI's internal face template (a round shape, two distinct "eyes," a "mouth"), it can overcome the distracting HSF noise. This is also highly consistent with human vision, where HSF information is vital for analyzing the fine features <em>of a face</em> once it has been detected.<table><thead><tr><th style=text-align:center><img alt=M src=/images/M.png><tbody><tr><td style=text-align:center><em>A illusory face on a can or clock mechanism that the LLM saw in all versions.</em></table><h4 id=test-4-the-illusory-robot><span style=color:orange> Test 4: The Illusory Robot </span></h4><p>This next test uses a common object that happens to have face-like features: a set of viewpoint binoculars. The results show another interesting form of interpretation by the model. In the LSF version, the blurry shape with two prominent circles triggers an anthropomorphic classification: <strong>"robot"</strong>. The model defaults to a familiar humanoid template. However, once the HSF details are available in the broadband and sharp versions, the model corrects its initial "guess" and accurately identifies the object as <strong>"viewpoint binoculars"</strong>.<table><thead><tr><th style=text-align:center><img alt=R src=/images/R.png><tbody><tr><td style=text-align:center><em>An LSF-induced "robot" is corrected into binoculars with more detail.</em></table><h4 id=test-5-the-holistic-face-paintings><span style=color:orange> Test 5: The Holistic Face Paintings </span></h4><p>Finally, I moved from pure pareidolia to a different kind of illusion: composite portraits, famously painted by artists like Giuseppe Arcimboldo. In these images, the face is <strong>intentionally</strong> constructed from other objects. These aren't really pareidolia in the same way; they are deliberate artistic constructions where recognizing the face requires <strong>holistic processing</strong>—seeing the overall arrangement rather than just the sum of the individual parts. How would the LLM fare?<p>The first painting is a face constructed from a landscape. Interestingly, the model identified a <strong>"large face"</strong> in both the broadband and high-frequency versions. This is a departure from the earlier pareidolia examples. Here, the individual components (trees, rocks) don't look like facial features on their own, but their careful arrangement creates a powerful holistic impression that the model was able to perceive, even with all the fine details present.<table><thead><tr><th style=text-align:center><img alt=P src=/images/P.png><tbody><tr><td style=text-align:center><em>A composite face, testing holistic perception.</em><br><em>Notably, the model identified the face in all three versions, even describing it as an 'optical illusion' in the BB.</em></table><p>I tried a second, similar painting of a shepherd in a landscape forming a face. The results were just as intriguing. In the full-detail versions, the model successfully identified both the whole (<strong>"Face"</strong>) and the parts (<strong>"Sheep"</strong>, <strong>"Shepherd"</strong>). It seemed to parse the image on multiple levels simultaneously.<p>However, an interesting twist occurred in the LSF version. The blur, which helped reveal faces in the pareidolia examples, seemed to <em>weaken</em> the illusion here. The model's top guess for the LSF version was <strong>"Tree"</strong>, not "Face". This might suggest that for these complex, deliberately constructed images, the precise arrangement and HSF details are actually <em>critical</em> for the holistic face to emerge, and blurring them can break the carefully crafted composition. It's a fascinating case where the general rule (LSF reveals faces) is reversed, highlighting the complexity of both human and machine perception.<table><thead><tr><th style=text-align:center><img alt=P2 src=/images/P2.png><tbody><tr><td style=text-align:center><em>Another composite face, where blur seemed to hinder, rather than help, perception.</em></table><h3 id=conclusion-and-final-thoughts><span style=color:orange> Conclusion and Final Thoughts </span></h3><p>For anyone working with or building on top of these AI systems, I believe understanding these kinds of behaviors is important. An AI's failure to see a pattern that is obvious to us—or its tendency to see one only under specific conditions like blurring—highlights the inherent differences in how they process visual information.<p>This method of probing with spatial frequencies and illusions could serve as a simple, fun, intuitive benchmark for tracking the progress of future vision models. As new architectures are developed, seeing how they handle these edge cases can tell us a lot about whether they are developing more robust, human-like perception or simply becoming better at pattern-matching their training data.<p>Of course, there are clear limitations here. I only used one model, Gemini 2.5 Pro, primarily because company I work provides free access to it. Other powerful models from OpenAI, Anthropic, or elsewhere might react to these images in completely different ways. The number of images was also small.<p>Also you might be realized that model's own distinction between a "Face" and a "Pareidolia Face". What is the difference? When the model uses the simple "Face" label, does it believe it's seeing a real person or animal? Is the "Pareidolia" tag an admission that it recognizes the illusion?<p>Perhaps the most important takeaway is the value of using novel stimuli. The real test for these models isn't showing them the famous "Church Face" again, but presenting them with the new, illusory faces we discover in our daily lives—a pattern in a coffee stain, the front of a new car, or a strangely-shaped vegetable. These "wild" pareidolia images, which the AI could not have been trained on, are the truest test of whether they are learning to <em>see</em> or just to <em>recognize</em>. And for me, that's an experiment that never gets old.</section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=https://engineering.videocall.rs/tags/llm/>llm</a><li><a href=https://engineering.videocall.rs/tags/pareidolia/>pareidolia</a><li><a href=https://engineering.videocall.rs/tags/ai/>AI</a><li><a href=https://engineering.videocall.rs/tags/vision/>vision</a><li><a href=https://engineering.videocall.rs/tags/perception/>perception</a><li><a href=https://engineering.videocall.rs/tags/illusion/>illusion</a></ul></nav></div></article></main><div class=giscus></div><script async crossorigin data-category=General data-category-id=DIC_kwDOL5Nyoc4CfU7n data-emit-metadata=0 data-input-position=bottom data-lang=en data-mapping=pathname data-reactions-enabled=1 data-repo=altunenes/altunenes.github.io data-repo-id=R_kgDOL5NyoQ data-strict=0 data-theme=preferred_color_scheme src=https://giscus.app/client.js></script></div>