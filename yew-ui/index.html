<!DOCTYPE html>
<html class="dark">
    <head>
        <meta charset="utf-8" />
        <title>videocall.rs</title>
        <meta name="viewport" content="width=device-width, user-scalable=no">
        <link data-trunk rel="copy-dir" href="./assets" />
        <link data-trunk rel="css" href="./static/leptos-style.css" />
        <link data-trunk rel="css" href="./static/tailwind.css" />
        <link data-trunk rel="css" href="./static/style.css" />
        <link data-trunk rel="css" href="./static/global.css">
        <!-- MediaStreamTrackProcessor polyfill -->
        <script>
            if (!self.MediaStreamTrackProcessor) {
              self.MediaStreamTrackProcessor = class MediaStreamTrackProcessor {
                constructor({track}) {
                  if (track.kind == "video") {
                    this.readable = new ReadableStream({
                      async start(controller) {
                        this.video = document.createElement("video");
                        this.video.srcObject = new MediaStream([track]);
                        await Promise.all([this.video.play(), new Promise(r => this.video.onloadedmetadata = r)]);
                        this.track = track;
                        this.canvas = new OffscreenCanvas(this.video.videoWidth, this.video.videoHeight);
                        this.ctx = this.canvas.getContext('2d', {desynchronized: true});
                        this.t1 = performance.now();
                      },
                      async pull(controller) {
                        while (performance.now() - this.t1 < 1000 / track.getSettings().frameRate) {
                          await new Promise(r => requestAnimationFrame(r));
                        }
                        this.t1 = performance.now();
                        this.ctx.drawImage(this.video, 0, 0);
                        controller.enqueue(new VideoFrame(this.canvas, {timestamp: this.t1}));
                      }
                    });
                  } else if (track.kind == "audio") {
                    this.readable = new ReadableStream({
                      async start(controller) {
                        this.ac = new AudioContext;
                        this.arrays = [];
                        function worklet() {
                          registerProcessor("mstp-shim", class Processor extends AudioWorkletProcessor {
                              process(input) { this.port.postMessage(input); return true; }
                          });
                        }
                        await this.ac.audioWorklet.addModule(`data:text/javascript,(${worklet.toString()})()`);
                        this.node = new AudioWorkletNode(this.ac, "mstp-shim");
                        this.ac.createMediaStreamSource(new MediaStream([track])).connect(this.node);
                        this.node.port.addEventListener("message", ({data}) => data[0][0] && this.arrays.push(data));
                      },
                      async pull(controller) {
                        while (!this.arrays.length) await new Promise(r => this.node.port.onmessage = r);
                        const [channels] = this.arrays.shift();
                        const joined = new Float32Array(channels.reduce((a, b) => a + b.length, 0));
                        channels.reduce((offset, a) => (joined.set(a, offset), offset + a.length), 0);
                        controller.enqueue(new AudioData({
                          format: "f32-planar",
                          sampleRate: this.ac.sampleRate,
                          numberOfFrames: channels[0].length,
                          numberOfChannels: channels.length,
                          timestamp: this.ac.currentTime * 1e6 | 0,
                          data: joined,
                          transfer: [joined.buffer]
                        }));
                      }
                    });
                  }
                }
              };
            }
        </script>
        <!-- MediaStreamTrackGenerator polyfill -->
        <script>
            if (!window.MediaStreamTrackGenerator) {
              window.MediaStreamTrackGenerator = class MediaStreamTrackGenerator {
                constructor({kind}) {
                  if (kind == "video") {
                    const canvas = document.createElement("canvas");
                    const ctx = canvas.getContext('2d', {desynchronized: true});
                    const track = canvas.captureStream().getVideoTracks()[0];
                    track.writable = new WritableStream({
                      write(frame) {
                        canvas.width = frame.displayWidth;
                        canvas.height = frame.displayHeight;
                        ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
                        frame.close();
                      }
                    });
                    return track;
                  } else if (kind == "audio") {
                    const ac = new AudioContext;
                    const dest = ac.createMediaStreamDestination();
                    const [track] = dest.stream.getAudioTracks();
                    track.writable = new WritableStream({
                      async start(controller) {
                        this.arrays = [];
                        function worklet() {
                          registerProcessor("mstg-shim", class Processor extends AudioWorkletProcessor {
                            constructor() {
                              super();
                              this.arrays = [];
                              this.arrayOffset = 0;
                              this.port.onmessage = ({data}) => this.arrays.push(data);
                              this.emptyArray = new Float32Array(0);
                            }
                            process(inputs, [[output]]) {
                              for (let i = 0; i < output.length; i++) {
                                if (!this.array || this.arrayOffset >= this.array.length) {
                                  this.array = this.arrays.shift() || this.emptyArray;
                                  this.arrayOffset = 0;
                                }
                                output[i] = this.array[this.arrayOffset++] || 0;
                              }
                              return true;
                            }
                          });
                        }
                        await ac.audioWorklet.addModule(`data:text/javascript,(${worklet.toString()})()`);
                        this.node = new AudioWorkletNode(ac, "mstg-shim");
                        this.node.connect(dest);
                        return track;
                      },
                      write(audioData) {
                        const array = new Float32Array(audioData.numberOfFrames * audioData.numberOfChannels);
                        audioData.copyTo(array, {planeIndex: 0});
                        this.node.port.postMessage(array, [array.buffer]);
                        audioData.close();
                      }
                    });
                    return track;
                  }
                }
              };
            }
        </script>
        <!-- Matomo -->
        <script>
            var _paq = window._paq = window._paq || [];
            /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
            _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
            _paq.push(['trackPageView']);
            _paq.push(['enableLinkTracking']);
            (function() {
            var u="//matomo.videocall.rs/";
            _paq.push(['setTrackerUrl', u+'matomo.php']);
            _paq.push(['setSiteId', '1']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
            })();
        </script>
        <!-- End Matomo Code -->
    </head>
    <body class="bg-background text-foreground">
    </body>
</html>
